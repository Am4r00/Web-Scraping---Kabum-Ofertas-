# Web Scraping Kabum - Python ğŸ–¥ï¸ğŸ”

## DescriÃ§Ã£o do Projeto
Este projeto tem como objetivo realizar um Web Scraping no site da Kabum, capturando informaÃ§Ãµes de produtos disponÃ­veis em promoÃ§Ã£o. O foco principal Ã© coletar dados como:

- Nome do Produto
- PreÃ§o
- CondiÃ§Ãµes de Parcelamento  

O projeto foi desenvolvido em Python, utilizando a biblioteca Selenium para automaÃ§Ã£o da navegaÃ§Ã£o e coleta dos dados.

AlÃ©m disso, o projeto possui um script adicional para realizar a limpeza dos dados coletados, removendo produtos duplicados e gerando um novo arquivo `.csv` final.

---

## Tecnologias Utilizadas
- Python 3.x  
- Selenium  
- Pandas  
- WebDriver (Google Chrome)

---

## Como Executar o Projeto

### 1. Clonar o repositÃ³rio:
```bash
git clone https://github.com/Am4r00/[https://github.com/Am4r00/Web-Scraping---Kabum-Ofertas-.git]
```
2. Instalar as dependÃªncias:
```bash
pip install -r requirements.txt
```
3. Executar o Web Scraping:
```bash
python main.py
```
4. Limpar os dados duplicados:
```bash
python limpeza.py
```
Estrutura do Projeto
```bash
â”œâ”€â”€ main.py           # Script principal que executa o Web Scraping
â”œâ”€â”€ scraper.py        # Classe responsÃ¡vel por realizar o scraping
â”œâ”€â”€ produto.py        # Classe que representa um produto
â”œâ”€â”€ limpeza.py        # Script para limpar dados duplicados
â”œâ”€â”€ produtos_kabum.csv     # Arquivo gerado com os produtos coletados
â”œâ”€â”€ produtosLimpo_kabum.csv # Arquivo final limpo
â””â”€â”€ requirements.txt  # DependÃªncias do projeto
```
Resultado Final
Ao final da execuÃ§Ã£o, os dados coletados dos produtos serÃ£o armazenados em um arquivo .csv chamado:
produtos_kabum.csv

E apÃ³s a limpeza de duplicados:
produtosLimpo_kabum.csv

ObservaÃ§Ãµes
Este projeto foi desenvolvido com finalidade educacional, A prÃ¡tica de Web Scraping deve respeitar as polÃ­ticas do site acessado.
Caso o site sofra alteraÃ§Ãµes em seu layout ou estrutura, o cÃ³digo pode necessitar de ajustes.

Autor
Desenvolvido por JoÃ£o Amaro ğŸš€
